# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

variables:
- group: databricks
- group: data-platform-kv
- group: mycelium

trigger:
- main

pool:
  vmImage: 'ubuntu-latest'
strategy:
  matrix:
    Python37:
      python.version: '3.8'

steps:
- task: UsePythonVersion@0
  inputs:
    versionSpec: '$(python.version)'
  displayName: 'Use Python $(python.version)'

- task: PipAuthenticate@1
  inputs:
    artifactFeeds: 'sibytes' 
    
- script: |
    python -m pip install --upgrade pip setuptools wheel twine
    pip install -r requirements.txt
    pip install -r dev_requirements.txt
  displayName: 'Install dependencies'

- script: |
    python setup.py sdist bdist_wheel
    python setup.py build_databricks_project
  displayName: 'Artifact creation'

- script: |
    export SKIP_INTEGRATION=True
    pip install .
    pytest test --junitxml=junit/test-results.xml --cov=mycelium --cov-report=xml --cov-report=html
  displayName: 'Unit Tests'

- task: PublishTestResults@2
  condition: succeededOrFailed()
  inputs:
    testResultsFiles: '**/test-*.xml'
    testRunTitle: 'Publish test results for Python $(python.version)'

- task: PublishCodeCoverageResults@1
  inputs:
    codeCoverageTool: Cobertura
    summaryFileLocation: '$(System.DefaultWorkingDirectory)/**/coverage.xml'
    reportDirectory: '$(System.DefaultWorkingDirectory)/**/htmlcov'

- task: CopyFiles@2
  inputs:
    SourceFolder: '$(Build.SourcesDirectory)'
    Contents: |
      dist/**
      deployment/**
      databricks/dist/**
    TargetFolder: '$(Build.ArtifactStagingDirectory)'

- task: PublishBuildArtifacts@1
  inputs:
    PathtoPublish: '$(Build.ArtifactStagingDirectory)'
    ArtifactName: 'drop'
    publishLocation: 'Container'
  displayName: 'Publish Build Artefacts'

- task: TwineAuthenticate@0
  inputs:
    artifactFeeds: 'Databricks/DTP'
    # externalFeeds: 'pypi'
  displayName: 'Authenticate Twine'

- script: |
    echo $(PYPIRC_PATH)
    cat $(PYPIRC_PATH)
    twine upload -r 'Databricks/DTP' --config-file $(PYPIRC_PATH) $(Build.SourcesDirectory)/dist/*
  continueOnError: true
  displayName: 'Publish to SiBytes Artefact Store'